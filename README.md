# ✈️ Azure 기반 End-to-End 데이터 플랫폼 구축

**🔗 상세 포트폴리오:** [juseong.dev](https://juseong.dev) (핵심 요약본)

**✍️ 기술 블로그:** [[블로그 링크]](https://juxpkr.github.io/projects/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-1/) (더 상세한 과정)


개인화된 데이터와 실시간 분석을 통해, 사용자에게 최적의 여행지를 추천하는 데이터 플랫폼 구축 프로젝트입니다.


```
TRAVEL-DATA-PIPELINE/
├── .venv/                                
├── .vscode/                              
├── _archive/                             # 팀원들이 담당했던 일부 데이터 수집/전처리 코드 
├── config/
│   └── master_country_crawler.json       # 국가, 도시를 매핑하기 위한 JSON파일
├── data_sources/                         # 핵심 비즈니스 로직: 데이터 수집/처리/변환 함수들
│   ├── __init__.py                       
│   ├── exchange_rate_crawler.py          # 환율 크롤링 로직 
│	  ├──	google_trend_crawler.py           # Google Trends 크롤링 로직
│	  └──	retry_utils.py                    # API 재시도 유틸리티 로직
├── functions/                            # 각 Azure Function의 트리거 및 바인딩 정의
│   ├── __init__.py                       
│   ├──exchange_rate_trigger.py           # 환율 데이터 수집을 위한 Timer Trigger 함수
│   ├──google_trends_processor.py         # Azure Queue Storage 메시지를 처리하고, Event Hubs로 전송하는 Consumer 함수 
│   └──google_trends_trigger.py           # Google Trends 데이터 수집을 위한 Producer 함수
├── local_output/                         # 로컬 테스트에서 생성되는 결과물 저장 디렉토리
│                                         
├── function_app.py                       # 모든 개별 함수들을 여기에 등록
│                                         
│                                  
├── host.json                             # Functions Host 전역 설정
├── local.settings.json                   # 로컬 환경 변수 설정 
├── requirements.txt                      # 프로젝트 의존성 목록
├── .funcignore                           
├── .gitignore                            
└── README.md                            
```


## 0. 프로젝트 미리보기

![프로젝트 데모](/images/시연영상.gif)


## 1. 프로젝트 개요 
여행자들은 여행을 떠나기 전, 환율, 항공권, 현지 물가 등 여러 서비스에 흩어져 연결되지 못했던 정보들을 직접 조합해야 하는 불편함을 겪습니다. 저는 이 문제를 해결하고자, 이기종 데이터들을 하나의 파이프라인으로 통합하여 객관적인 '여행지 매력도 점수'를 산출하고, 이를 바탕으로 사용자에게 최적화된 여행지를 추천하는 데이터 플랫폼을 구축했습니다.
### 1.1 주요 기술 스택 :
- `Azure Databricks` `Apache Spark` `Azure Functions` `Azure Event Hubs` `Azure Stream Analytics` `Azure Blob Storage`  `Unity Catalog` `Power BI` `Python` `SQL`
### 1.2 주요 기능 및 데이터 소스
이 프로젝트는 단순히 데이터를 수집하는 것을 넘어, 사용자의 복합적인 의사결정을 돕기 위해 다음과 같은 핵심 질문에 데이터로 답하고자 했습니다.
- **비용 (Cost)**: 지금 여행을 떠난다면, 실질적인 총비용은 얼마인가? (환율, 항공권, 현지 물가) 
- **만족도 (Satisfaction)**: 지금 가장 인기 있고, 날씨가 좋은 여행지는 어디인가? (트렌드 지수, 날씨, 강수량)
- **안전 (Safety)**: 나의 여행지는 안전한가? (여행 안전 정보)
## 2. 아키텍처: 실시간 처리의 한계와 하이브리드 설계

이 프로젝트의 핵심 기술 과제는, 서로 다른 주기와 형식을 가진 여러 데이터를 어떻게 효율적으로 통합하여, '준실시간'의 비즈니스 요구사항을 만족시키는가였습니다. 이 문제를 해결하기 위해, 아키텍처는 다음과 같이 진화했습니다.

### 2.1 초기 아키텍처(Before): '단일 스트림' 처리 방식의 한계 

![](/images/readme(1).png)

초기 아키텍처는 "모든 데이터를 단일 실시간 스트림으로 처리하여 즉각적인 인사이트를 얻는다"는 이상적인 목표로 설계되었습니다. 각 Azure 서비스는 이 목표를 위해 다음과 같은 역할을 수행하도록 구성했습니다.

- **데이터 수집 (`Azure Function App`):** 다양한 외부 데이터 소스(웹 크롤링, 외부 API)로부터 데이터를 자동으로 수집하는 엔트리 포인트.
- **데이터 허브 (`Azure Event Hubs`):** 수집된 모든 데이터를 실시간으로 안정적으로 모으는 중앙 통로.
- **중앙 처리 엔진 (`Azure Stream Analytics`):** `Event Hubs`로 모인 모든 데이터 스트림을 실시간으로 분석, 통합하고 최종 '매력도 점수'까지 계산하는 핵심 역할.
- **최종 시각화 (`Power BI`):** `ASA`에서 처리된 최종 결과를 사용자에게 보여주는 대시보드.

하지만, 이 설계는 실제 데이터를 다루는 과정에서 다음과 같은 근본적인 한계점들을 가지고 있었습니다.

- **복잡한 조인 및 다양한 세분성 데이터 처리의 제약** 월별/도시별/국가별 데이터와 같은 주기성 데이터와 실시간 환율 및 트렌드 데이터를 복합적으로 조인해야 했습니다. `Stream Analytics`는 실시간 스트림 처리에 강점을 가졌지만, 이처럼 다양한 시간적, 공간적 세분성을 가진 여러 데이터셋을 다단계로 조인하고, 정교한 시간 윈도우(Window) 함수를 적용하는 데는 명확한 기능적 제약이 있었습니다. `SQL`과 유사한 쿼리 언어는, 배치 처리 환경의 ETL 기능에 미치지 못했습니다.
- **재처리 및 디버깅의 어려움** 실시간 스트림 데이터의 특성상, 쿼리 로직에 오류가 발생하거나 데이터 재처리가 필요할 경우 디버깅 및 재실행이 쉽지 않았습니다. 이는 개발 및 유지보수 효율을 크게 저하시킬 수 있는 리스크였습니다.
### 2.2 해결 전략 및 최종 아키텍처

이러한 한계를 극복하기 위해, 하이브리드 아키텍처로 재설계를 주도했습니다. `Stream Analytics`의 역할은 축소하고, 복잡한 ETL 처리를 위해 `Databricks`를 도입하여 전체 파이프라인의 효율성과 견고성을 높였습니다.
![](/images/readme(2).png)

#### 2.2.1 데이터 레이크 구성 (원시 데이터 저장)
- `Stream Analytics`를 통해 `Event Hubs`에서 유입되는 모든 원시 데이터를 `Azure Blob Storage`로 전달하여 저장했습니다. `Blob Storage`는 비용 효율적인 대규모 저장소로, 향후 더 복잡한 배치 처리를 위한 데이터 레이크의 원시(Raw) 레이어 역할을 수행합니다. 
#### 2.2.2 실시간 데이터 스트리밍 (Power BI연동)
- 환율, 날씨와 같이 즉각적인 변화를 시각화해야 하는 일부 데이터는 `Stream Analytics`에서 간단히 정제하여 `Power BI` 대시보드로 직접 스트리밍했습니다. 이를 통해 실시간 환율 변동이나 현재 날씨와 같은 지표를 대시보드에서 즉시 확인할 수 있도록 하여, `Stream Analytics`의 실시간 스트림 처리 강점을 활용했습니다.
#### 2.2.3  배치 데이터 처리 (Databricks 활용)
- `Azure Blob Storage`에 저장된 원시 데이터를 활용하여, `Databricks`의 `PySpark`를 통해 매일 정해진 시간에 배치 방식으로 데이터를 처리했습니다. 이 과정에서, 서로 다른 주기와 형식을 가진 여러 데이터 소스를 통합하고, 복잡한 비즈니스 로직을 적용하여 최종 '여행지 매력도 점수'를 계산했습니다. 배치 처리를 통해, 실시간 스트리밍 환경에서는 구현하기 어려웠던 정교한 데이터 변환과 대규모 조인 작업을 안정적으로 수행할 수 있었습니다.
#### 2.2.4 데이터 거버넌스 및 관리 (Unity Catalog)
- `Databricks`에서 처리된 최종 데이터는 신뢰성과 ACID 트랜잭션을 보장하는 `Delta Lake` 포맷으로 저장하고, 이 데이터를 `Databricks Unity Catalog`에 테이블로 등록하여 중앙에서 관리했습니다. 이를 통해, 데이터의 출처를 추적하고 사용자별 접근 권한을 관리하는 등 데이터 거버넌스의 기반을 마련했으며, `Power BI`에서의 데이터 접근성과 신뢰도를 크게 향상시켰습니다.
## 3. 핵심 구현 내용

### 3.1 데이터 수집 : `429` 에러 해결 (`Azure Functions`)
프로젝트의 가장 치명적인 장애 포인트는, `Google Trends` 데이터를 수집할 때 발생하는 `429 Too Many Requests Error`였습니다. 저는 이 문제를 해결하기 위해, 다음과 같은 단계적 분석을 통해 근본적인 해결책을 설계했습니다.
#### 3.1.1 단순 지연 : 
처음에는 `time.sleep()` 함수를 사용하여 API 호출 간에 대기 시간을 두는 방식으로 문제를 해결하려 했습니다. 그러나 동일한 IP주소에서 발생하는 순차적인 요청은 Google의 감지 시스템을 우회할 수 없어 실패했습니다.
#### 3.1.2 재시도 로직 도입 :
다음으로 `tenacity` 라이브러리를 도입하여 실패한 요청을 자동으로 재시도하도록 로직을 강화했습니다. 이를 통해 일시적인 오류에는 대응할 수 있었지만, 단일 IP 주소에서의 요청 빈도 제한이라는 근본적인 문제는 여전히 해결하지 못했습니다.
#### 3.1.3 분산 처리 아키텍처 :
결국, 근본적인 해결을 위해 Producer-Consumer 패턴 기반의 분산 처리 아키텍처를 설계했습니다.
- `Azure Functions`의 다중 인스턴스 자동 스케일링을 활용하여 여러 인스턴스가 동시에 실행되도록 했습니다.
- 각 인스턴스가 서로 다른 아웃바운드 IP 주소를 사용할 가능성을 높여, Google의 요청 제한을 효과적으로 회피했습니다.
- `Azure Queue Storage`를 통해 요청을 분산시키고, `random.uniform()`함수로 각 인스턴스의 API 호출 시작 시점을 무작위로 지연시킴으로써 파이프라인의 안정성을 극대화 했습니다.

이러한 단계적인 시도와 최종적인 분산 처리 아키텍처 도입을 통해 `429`에러를 완전히 해결하고, 61개 국가의 Google Trends 데이터를 안정적으로 수집할 수 있었습니다.
### 3.2 실시간/정적 데이터 처리 (`Stream Analytics` & `Databricks`)

데이터 수집 단계가 안정화된 후, 수집된 데이터를 처리하기 위해 초기 아키텍처의 한계를 보완하는 전략을 수립했습니다. 데이터 파이프라인은 실시간 처리와 정적(배치) 처리의 두 가지 흐름으로 나뉘어 구현되었습니다.
- **실시간 데이터 처리 (`Azure Stream Analytics`)** : 실시간으로 수집되는 환율 날씨 등 변동성이 높은데이터를 즉시 처리하는데 활용했습니다. `ASA`의 스트리밍 `SQL`을 사용하여 `Event Hubs`에서 들어오는 실시간 데이터 스트림을 간단하게 필터링하고 변환한 후 `Power BI`로 출력했습니다.
- **배치 데이터 처리 (`Azure Databricks`)**: `Event Hubs`에서 들어오는 데이터를 `Azure Blob Storage`에 저장한 후, `Databricks`의 `PySpark` 를 활용하여 매일 한 번씩 배치 방식으로 데이터를 통합하고, 복잡한 비즈니스 로직에 따라 최종 여행지 매력도 점수를 계산했습니다.

### 3.3 데이터 저장소 및 시각화 (`Delta Lake` &` Power BI`)

- **데이터 저장 및 관리**: `Databricks`에서 처리된 최종 데이터는 ACID 트랜잭션을 보장하는 `Delta Lake` 포맷으로 저장하여 데이터의 신뢰성을 확보했습니다. 더 나아가, 이 데이터를 단순 파일이 아닌 `Unity Catalog`에 테이블로 등록하여, 데이터의 출처를 추적하고 사용자별 접근 권한을 관리하는 등 데이터 거버넌스의 기반을 마련했습니다.
- **시각화 및 서비스** : `Unity Catalog`에 저장된 최종 데이터를 `Power BI`에 연결하여, 사용자가 여행지 추천 결과를 직관적으로 확인할 수 있는 대시보드를 구축했습니다.
## 4. 결론

이 프로젝트는 단순히 기능을 구현하는 것을 넘어, 데이터 엔지니어링의 핵심적인 세 가지 가치를 증명하는 과정이었습니다.

- **안정성:** 불안정한 외부 API 환경 속에서, 429 Error를 원천적으로 해결하는 분산 수집 아키텍처를 직접 설계하고 구현하여, 데이터 유실 없는 안정적인 파이프라인의 기반을 마련했습니다.
- **신뢰도:** 초기 아키텍처의 설계적 결함을 진단하고 하이브리드 아키텍처로 재설계했으며, `Unity Catalog` 기반의 데이터 거버넌스를 통해 신뢰할 수 있는 데이터 처리 및 관리의 기반을 구축했습니다.
- **가치 창출:** '마스터 데이터' 설계와 `LEFT JOIN` 전환을 통해, 기존에 버려지던 90%의 데이터를 분석 가능하도록 전환하여, 데이터 기반 의사결정의 분석 커버리지를 100%로 확대했습니다.

이 프로젝트는 저에게, 어떤 복잡한 데이터 문제라도 아키텍처 관점에서 분석하고, 최적의 기술 스택을 조합하여 해결할 수 있다는 자신감을 주었습니다.

### 4.1 나의 역할 및 기여

이 프로젝트에서 저는 End-to-End 데이터 파이프라인의 핵심인 데이터 수집, 처리, 저장 아키텍처 전체를 단독으로 책임지고 설계 및 구현했습니다. 팀원들은 제가 설계한 아키텍처 위에서 동작하는 일부 데이터 소스(항공권, 물가 등)의 리서치 및 수집 스크립트 작성과, 최종 산출물인 `Power BI` 대시보드 제작을 담당했습니다. 저는 이 과정에서 기술적인 리딩과 방향 제시를 통해 프로젝트가 성공적으로 마무리되도록 이끌었습니다.
- (참고: 팀원들이 담당했던 일부 데이터 수집/전처리 코드는 현재 메인 파이프라인에는 통합되지 않았으며, `_archive` 폴더에 별도로 보관되어 있습니다.)
## 5. 상세 내용
프로젝트의 더 자세한 개발 과정과 기술 결정은 아래 블로그 포스팅에서 확인하실 수 있습니다.

[[Azure 기반 End-to-End 데이터 파이프라인] 나만의 최적 여행지 추천 시스템 구축기(1) : 프로젝트 소개 및 아키텍처 - Dev Blog](https://juxpkr.github.io/projects/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-1/)



