# ✈️ 나만의 최적 여행지 추천 시스템 - travel-data-pipiline

개인화된 데이터와 준실시간 분석을 통해 여행의 패러다임을 바꾸는 End-to-End 데이터 파이프라인 구축 프로젝트
```
TRAVEL-DATA-PIPELINE/
├── .venv/                                # 파이썬 가상 환경 
├── .vscode/                              # VS Code 설정 
├── config/
│   └── master_country_crawler.json       # 국가, 도시를 매핑하기 위한 JSON파일
├── data_sources/                         # 핵심 비즈니스 로직: 데이터 수집/처리/변환 함수들
│   ├── __init__.py                       # 파이썬 패키지임을 알리는 빈 파일
│   ├── exchange_rate_crawler.py          # 환율 크롤링 로직
│	├──	flight_avg_merge.py               # 항공권 평균 가격 데이터 병합 로직(팀원 담당)
│	├──	flight_price_preprocessing.py     # 항곤권가격 전처리 로직(팀원 담당) 
│	├──	google_trend_crawler.py           # Google Trends 크롤링 로직
│	└──	retry_utils.py                    # API 재시도 유틸리티 로직
├── functions/                            # 각 Azure Function의 트리거 및 바인딩 정의
│   ├── __init__.py                       # 파이썬 패키지임을 알리는 빈 파일
│   ├──exchange_rate_trigger.py           # 환율 데이터 수집을 위한 Timer Trigger 함수
│   ├──google_trends_processor.py         # Queue에도착한 메시지를 처리하는 Consumer 함수 
│   └──google_trends_trigger.py           # Google Trends 데이터 수집을 위한 Producer 함수
├── local_output/                         # 로컬 테스트에서 생성되는 결과물 저장 디렉토리
│                                         # gitignore에 추가되어 Git에 커밋되지 않음
├── function_app.py                      # Azure Functions 앱의 중심
│                                        # 모든 개별 함수들을 여기에 등록
│                                  
├── host.json                            # Functions Host 전역 설정
├── local.settings.json                  # 로컬 환경 변수 설정 
├── requirements.txt                     # 프로젝트 의존성 목록
├── .funcignore                          # Azure 배포 시 제외할 파일/폴더 지정
├── .gitignore                           # Git 버전 관리 시 제외할 파일/폴더 지정
└── README.md                            # 프로젝트 설명
```


## 0. 프로젝트 미리보기

## 1. 프로젝트 개요 

여행자들은 여행을 떠나기 전, 수많은 정보 속에서 최적의 선택지를 찾는 데 어려움을 겪습니다. 저는 이러한 고객의 불편함을 해결하고자 **'나만의 최적 여행지 추천 시스템'** 을 구축했습니다. 이 시스템은 각 국가의 환율, 항공권 가격, 날씨 등 변동성이 큰 데이터를 준실시간으로 통합 분석하여 **'여행지 매력도 점수'** 를 산출하고, 이를 바탕으로 사용자에게 최적화된 여행지를 추천합니다.
### 1.1 주요 기술 스택 :
- `Python` `Azure Functions` `Azure Event Hubs` `Databricks(PySpark)` `Delta Lake` `Azure Stream Analytics` `Azure Blob Storage` `Power BI` 
### 1.2 주요 기능 및 데이터 소스
단순히 저렴한 여행지를 찾는 것을 넘어, 가격 대비 만족도와 개인의 선호도를 반영하기 위해 다음과 같은 복합적인 요소를 분석했습니다.
- **환율**: 5분 간격의 준실시간 환율 변동을 반영하여 현지에서 실질적으로 체감하는 비용을 정확히 계산합니다.
- **항공권 가격**: 원하는 시점의 최저가 항공권을 찾아내 여행 시작 비용을 예측합니다.
- **현지 물가**: 도시별 평균 식비, 숙박비, 교통비 등 현지 생활비를 파악하여 총 예산을 추정합니다.
- **트렌드 지수**: 지금 사람들이 가장 많이 검색하고 관심 갖는 “뜨는” 여행지를 파악합니다.
- **여행 안전 정보**: 외교부 데이터를 기반으로 위험 지역은 추천에서 제외하고 안전한 곳만 선별합니다.
- **강수량**: 여행 시기별 우기/건기 정보를 반영하여 쾌적한 여행 경험을 보장합니다.
- **날씨**: 준실시간 날씨를 제공하여, 현재 특정 도시의 날씨 정보를 제공합니다.
## 2. 아키텍처 개선 과정

### 2.1 초기 아키텍처 및 한계 

방대한 데이터를 수집하고, 실시간으로 처리하며, 최종적으로는 사용자에게 보여주는 모든 과정은 클라우드 기반의 End-to-End 데이터 파이프라인으로 구축되었습니다.
![](/images/readme(1).png)

초기 구상 단계에서 각 Azure 서비스의 역할은 다음과 같았습니다.
- **데이터 수집** **(`Azure Function App`)**: 다양한 외부 데이터 소스 (웹 크롤링, 외부API)로 부터 데이터를 자동으로 가져옵니다.
- **데이터 허브** **(`Azure Event Hubs`)** : 수집된 모든 데이터를 실시간으로 안정적으로 모으는 중앙 통로 역할을 합니다.
- **실시간 데이터 처리 (`Azure Stream Analytics`)** : Event Hubs에서 모인 데이터를 실시간으로 분석, 통합하고 ‘매력도 점수’를 계산하며, 모든 복합적인 조인 및 계산을 여기서 처리합니다.
- **데이터 시각화 및 서비스(`Power BI`)** : 처리된 데이터를 기반으로 대시보드를 구축하고, 사용자에게 추천 서비스를 제공합니다. (향후 웹 애플리케이션 또는 RAG 챗봇으로 확장 가능성을 염두에 두었습니다.)

하지만, 실제 데이터를 다루면서 **`Stream Analytics`의 한계**를 확인했습니다.

- **복잡한 조인 및 다양한 세분성 데이터 처리의 제약**: 월별/도시별/국가별 데이터와 같은 주기성 데이터와 실시간 환율 및 트렌드 데이터를 복합적으로 조인해야 했고, 각 데이터셋은 서로 다른 시간적, 공간적 세분성을 가지고 있었습니다. `Stream Analytics`는 실시간 스트림 처리에 강점을 가졌지만, 이처럼 **다양한 시간적,공간적 세분성을 가진 여러 데이터셋을 다단계로 조인하고, 정교한 시간 윈도우(Window) 함수를 적용하는 데는 기능적 제약이 있었습니다.** SQL과 유사한 쿼리 언어를 사용하지만, 배치 처리 환경에서 제공되는 다양한 ETL(Extract, Transform, Load) 기능에는 미치지 못했습니다.
- **재처리 및 디버깅의 어려움**: 실시간 스트림 데이터의 특성상, 쿼리 로직에 오류가 발생하거나 데이터 재처리가 필요할 경우 디버깅 및 재실행이 쉽지 않아 개발 및 유지보수 효율이 저하될 것으로 판단했습니다.
### 2.2 해결 전략 및 최종 아키텍처

이러한 한계를 극복하기 위해 **`Databricks`를 도입**하고 아키텍처를 재설계했습니다. `Stream Analytics`의 역할을 재정의하여 파이프라인의 효율성과 견고성을 높였습니다.
![](/images/readme(2).png)

#### 2.2.1 원시 데이터 저장 (Data Lake 구성)
- `Stream Analytics`를 통해 `Event Hubs`에서 유입되는 **모든 원시 데이터를 `Azure Blob Storage`로 전달하여 저장**했습니다. `Blob Storage`는 비용 효율적인 대규모 저장소로, 향후 더 복잡한 배치 처리를 위한 데이터 레이크의 원시(Raw) 레이어 역할을 수행합니다. 
#### 2.2.2 실시간 데이터 스트리밍 (Power BI연동)
- 환율, 날씨와 같이 즉각적인 변화를 시각화해야 하는 일부 데이터는 `Stream Analytics`에서 간단히 정제하여 **`Power BI` 대시보드로 직접 스트리밍**했습니다. 이를 통해 실시간 환율 변동이나 현재 날씨와 같은 지표를 대시보드에서 즉시 확인할 수 있었습니다. `Stream Analytics`의 실시간 스트림 처리 강점을 활용한 방안이었습니다.

## 3. 핵심 구현 내용

### 3.1 데이터 수집 : `429` 에러 해결 (`Azure Functions`)
프로젝트의 핵심 데이터인 Google Trends를 안정적으로 수집하는 과정에서, Google의 강력한 요청 제한으로 인해 `429 Too Many Requests` 오류가 빈번하게 발생했습니다. 이 문제를 해결하기 위해 다음과 같은 단계적인 접근을 시도했습니다.

#### 3.1.1 단순 지연 : 
처음에는 `time.sleep()` 함수를 사용하여 API 호출 간에 대기 시간을 두는 방식으로 문제를 해결하려 했습니다. 그러나 동일한 IP주소에서 발생하는 순차적인 요청은 Google의 감지 시스템을 우회할 수 없어 실패했습니다.
#### 3.1.2 재시도 로직 도입 :
다음으로 `tenacity` 라이브러리를 도입하여 실패한 요청을 자동으로 재시도하도록 로직을 강화했습니다. 이를 통해 일시적인 오류에는 대응할 수 있었지만, 단일 IP 주소에서의 요청 빈도 제한이라는 근본적인 문제는 여전히 해결하지 못했습니다.
#### 3.1.3 분산 처리 아키텍처 :
결국, 근본적인 해결을 위해 **생산자-소비자 패턴** 기반의 분산 처리 아키텍처를 설계했습니다.
- `Azure Functions`의 **다중 인스턴스 자동 스케일링**을 활용하여 여러 인스턴스가 동시에 실행되도록 했습니다.
- 각 인스턴스가 서로 다른 아웃바운드 IP 주소를 사용할 가능성을 높여, Google의 요청 제한을 효과적으로 회피했습니다.
- `Azure Queue Storage`를 통해 요청을 분산시키고, `random.uniform()`함수로 각 인스턴스의 API 호출 시작 시점을 무작위로 지연시킴으로써 파이프라인의 안정성을 극대화 했습니다.

이러한 단계적인 시도와 최종적인 분산 처리 아키텍처 도입을 통해 `429`에러를 완전히 해결하고, 61개 국가의 Google Trends 데이터를 안정적으로 수집할 수 있었습니다.
### 3.2 실시간/정적 데이터 처리 (`Stream Analytics` & `Databricks`)

데이터 수집 단계가 안정화된 후, 수집된 데이터를 처리하기 위해 초기 아키텍처의 한계를 보완하는 전략을 수립했습니다. 데이터 파이프라인은 **실시간 처리와 정적(배치) 처리**의 두 가지 흐름으로 나뉘어 구현되었습니다.
- **실시간 데이터 처리 (`Azure Stream Analytics`)** : 실시간으로 수집되는 환율 날씨 등 변동성이 높은데이터를 즉시 처리하는데 활용했습니다. `ASA`의 스트리밍 `SQL`을 사용하여 `Event Hubs`에서 들어오는 실시간 데이터 스트림을 간단하게 필터링하고 변환한 후 `Power BI`로 출력했습니다.
- **정적 데이터 처리 (`Azure Databricks`)**: `Event Hubs`에서 들어오는 데이터를 `Azure Blob Storage`에 저장한 후, **`Databricks`의 `PySpark`** 를 활용하여 매일 한 번씩 배치 방식으로 데이터를 통합하고, 복잡한 비즈니스 로직에 따라 최종 **여행지 매력도 점수**를 계산했습니다.

### 3.3 데이터 저장소 및 시각화 (`Delta Lake` &` Power BI`)

- **데이터 저장소** : 복잡한 변환 작업을 거쳐 `Databricks`에서 최종 처리된 데이터는 `Delta Lake`에 저장했습니다. `Apache Spark`와 통합된 `Delta Lake`의 **ACID 트랜잭션** 기능을 활용하여 데이터의 신뢰성을 확보하고 데이터 불일치 문제를 방지했습니다.
- **시각화 및 서비스** : `Delta Lake`에 저장된 최종 데이터를 `Power BI`에 연결하여, 사용자가 여행지 추천 결과를 직관적으로 확인할 수 있는 대시보드를 구축했습니다.
## 4. 성과 및 결론

이 프로젝트를 통해 저는 단순한 기술 습득을 넘어, 데이터 엔지니어링의 본질적인 역량들을 기를 수 있었습니다.

- **기술적 도전과 문제 해결**: `429 Too Many Requests` 에러라는 현실적인 문제에 직면하여, 초기 시도부터 **`Azure Functions`의 분산 처리 아키텍처**를 설계하고 구현하기까지의 과정은 저의 문제 분석 및 해결 능력을 크게 성장시켰습니다.

- **아키텍처 설계와 유연성**: 초기 `Azure Stream Analytics`의 한계를 빠르게 파악하고, **`Databricks`를 도입하여 아키텍처를 재설계**함으로써 문제에 맞춰 최적의 솔루션을 찾아내는 유연한 사고와 실무적 통찰력을 길렀습니다.

- **End-to-End 파이프라인 완성**: 데이터 수집부터 최종 시각화까지, 클라우드 기반의 파이프라인 전체를 제 손으로 구축했습니다. 특히 **`Databricks(PySpark)`** 를 활용해 데이터를 안정적으로 처리하고, 최종 결과를 **Power BI** 로 최종 결과물을 시각화하면서, 복잡한 데이터를 누구나 쉽게 이해할 수 있는 정보로 만드는 과정에 큰 보람을 느꼈습니다.

이 프로젝트는 저에게 단순한 포트폴리오를 넘어, 어떤복잡한 데이터 문제라도 아키텍처 관점에서 분석하고, 최적의 기술 스택을 조합하여 해결할 수 있다는 자신감을 얻었습니다. 

### 4.1 나의 역할 및 기여
이 프로젝트에서 저는 **End-to-End 데이터 파이프라인의 핵심인 데이터 수집, 처리, 저장 과정을 단독으로 책임지고 완성**했습니다.

-  **데이터 파이프라인 설계 및 구축**: `429 Too Many Requests` 에러를 해결하기 위한 **분산 처리 아키텍처 설계**와 `Azure Stream Analytics`의 한계를 극복하고 `Databricks`를 도입하는 **아키텍처 변경을 주도**했습니다. `Azure Functions`, `Event Hubs`, `Databricks`, `Delta Lake`를 활용하여 파이프라인의 모든 기술적 난관을 해결했습니다.
- **데이터 처리 및 분석**: `PySpark`를 사용하여 다양한 이기종 데이터를 통합하고, 복잡한 비즈니스 로직에 따라 여행지 매력도 점수를 계산하는 핵심 로직을 구현했습니다.

항공권 가격, 현지 물가, 강수량, 날씨, 여행 안전 경보 데이터 수집과 최종 결과물인 `Power BI` 대시보드 제작은 팀원들과 협업하여 프로젝트를 성공적으로 마무리했습니다.
## 5. 상세 내용
프로젝트의 더 자세한 개발 과정과 기술 결정은 아래 블로그 포스팅에서 확인하실 수 있습니다.

[[Azure 기반 End-to-End 데이터 파이프라인] 나만의 최적 여행지 추천 시스템 구축기(1) : 프로젝트 소개 및 아키텍처 - Dev Blog](https://juxpkr.github.io/projects/%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-1/)



